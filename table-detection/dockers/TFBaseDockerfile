# Use an official Python runtime as a parent image
FROM ubuntu:16.04

RUN apt-get update && apt-get install -y --no-install-recommends \
        apt-utils \
        curl \
        git \
        python \
        python3.5 \
        python3-pip \
        software-properties-common \
        unzip \
        wget \
        sudo \
        python-tk \
        && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install pip
RUN curl -O https://bootstrap.pypa.io/get-pip.py && \
    python3 get-pip.py && \
    rm get-pip.py

# Install basic python requirements
RUN pip3 --no-cache-dir install --upgrade \
        Flask \
        numpy \
	requests \
        matplotlib \
        pillow \
        Cython \
        contextlib2 \
        lxml

# Install protobuf

RUN curl -OL https://github.com/google/protobuf/releases/download/v3.6.0/protoc-3.6.0-linux-x86_64.zip && \
unzip protoc-3.6.0-linux-x86_64.zip -d protoc3 && \
sudo mv protoc3/bin/* /usr/local/bin/  && \
sudo mv protoc3/include/* /usr/local/include/ && \
sudo chmod +x /usr/local/bin/protoc && \
chown `whoami` /usr/local/bin/protoc && \
chown -R `whoami` /usr/local/include/google

# Install tensorflow:1.9.0 for python 3.5
ENV TF_BINARY_URL https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.9.0-cp35-cp35m-linux_x86_64.whl
RUN pip3 --no-cache-dir install $TF_BINARY_URL

# upload the object inference to git and then curl from there 
RUN git clone https://github.com/tensorflow/models.git
ENV MODEL=/models/research
WORKDIR $MODEL
RUN protoc object_detection/protos/*.proto --python_out=.
    
ENV PYTHONPATH=$PYTHONPATH:$MODEL:$MODEL/slim

# Run testcases when the container launches
CMD ["python3","object_detection/builders/model_builder_test.py"]
